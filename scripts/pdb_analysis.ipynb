{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from folding.utils.ops import check_and_download_pdbs, check_if_directory_exists\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "import math\n",
    "from pprint import pprint\n",
    "from Bio.PDB import PDBParser\n",
    "import concurrent.futures\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETE_IDs_FILE = \"./pdb_ids_complete.pkl\"\n",
    "INCOMPLETE_IDs_FILE = \"./pdb_ids_incomplete.pkl\"\n",
    "NOT_DOWNLOADABLE_IDs_FILE = \"./pdb_ids_not_downloadable.pkl\"\n",
    "\n",
    "COMPLETE_PDB_FILES = \"./complete_pdbs/\"\n",
    "INCOMPLETE_PDB_FILES = \"./incomplete_pdbs/\"\n",
    "\n",
    "\n",
    "def analyze_pdb_batch(pdb_ids: dict, pdb_directory: str, delete_pdb: bool = False):\n",
    "    # Creating empty pandas dataframe\n",
    "    data_dict = defaultdict()\n",
    "\n",
    "    def analyze_pdb(pdb_id: str):\n",
    "        nonlocal data_dict, delete_pdb, pdb_directory\n",
    "        # Downloading the PDB file\n",
    "        download_pdb(pdb_directory, pdb_id=pdb_id + \".pdb\")\n",
    "        parser = PDBParser()\n",
    "\n",
    "        structure = parser.get_structure(pdb_id, f\"{pdb_directory}{pdb_id}.pdb\")\n",
    "\n",
    "        # Get all atoms\n",
    "        atoms = [atom for atom in structure.get_atoms()]\n",
    "\n",
    "        # The number of atoms in the molecule\n",
    "        num_atoms = len(atoms)\n",
    "\n",
    "        if delete_pdb:\n",
    "            # Deleting the pdb file\n",
    "            os.remove(f\"{pdb_directory}{pdb_id}.pdb\")\n",
    "\n",
    "        data_dict[pdb_id] = num_atoms\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(analyze_pdb, pdb_id)\n",
    "            for k, v in pdb_ids.items()\n",
    "            for pdb_id in v\n",
    "        ]\n",
    "        concurrent.futures.wait(futures)\n",
    "\n",
    "    # Creating dataframe from data_dict\n",
    "    df = pd.DataFrame.from_dict(data_dict, orient=\"index\", columns=[\"Number of Atoms\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def download_pdb(pdb_directory: str, pdb_id: str) -> bool:\n",
    "\n",
    "    url = f\"https://files.rcsb.org/download/{pdb_id}\"\n",
    "    path = os.path.join(pdb_directory, f\"{pdb_id}\")\n",
    "\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "\n",
    "        check_if_directory_exists(output_directory=pdb_directory)\n",
    "        with open(path, \"w\") as file:\n",
    "            file.write(r.text)\n",
    "\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring complete pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(COMPLETE_IDs_FILE, \"rb\") as f:\n",
    "#     complete_pdb_ids = pkl.load(f)\n",
    "\n",
    "# mini_batch = {k: complete_pdb_ids[k] for k in list(complete_pdb_ids)[:2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = analyze_pdb_batch(complete_pdb_ids, delete_pdb=False)\n",
    "# df.to_csv(\"complete_pdbs_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring incomplete pdbs\n",
    "- ~177k incomplete pdb files; we'll sample 20% to have around the same number of datapoints as the complete pdbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INCOMPLETE_IDs_FILE, \"rb\") as f:\n",
    "    incomplete_pdb_ids = pkl.load(f)\n",
    "\n",
    "\n",
    "# Sampling 20%\n",
    "sampled_ids = defaultdict(list)\n",
    "for k, v in incomplete_pdb_ids.items():\n",
    "    sampled_ids[k] = np.random.choice(\n",
    "        v, math.ceil(len(v) * 0.01), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing\n",
    "df_incomplete = analyze_pdb_batch(\n",
    "    incomplete_pdb_ids, pdb_directory=INCOMPLETE_PDB_FILES, delete_pdb=False\n",
    ")\n",
    "df_incomplete.to_csv(\"incomplete_pdbs_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
